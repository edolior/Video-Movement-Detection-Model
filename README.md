# Welcome to: Video Movement Detection Model

<p align="center"> Dance embodies artistic expression and when technology intertwines with this form of expression, it represents a unique domain of investigation and research. Numerous studies have attempted to automate dance attributes to capture motion patterns of dancers, categorize and classify dance styles, as well as video dancing generations. Despite recent years of concerted efforts by researchers in the dance video recognition domain, no fully capable detection model has been deployed to characterize efficiently changes in dance over time. In this paper, a video motion detector model tracks and evaluates dancing movement sequences by frames of videos by generation of multiple types of time-series datasets. The goal is to characterize and capture various dancing motion patterns and to achieve dominant representative features of dance styles during recent decades. Each dance is divided into multiple components including, unique body movements, aggregated body parts distances, recurrent movement patterns, types of movement gestures by their coordinates and more. Large datasets are generated from each dance comprised of many different types of dynamic pose changes. Analyzing and extracting relevant and dominant dancing attributes serves as a big challenge, however this model has obtained significant differences results. Ten dominant dance movement features are defined, extracted and transformed into time-series representation to the utilization of recognition in dance automation. This dance structure embedded representation is evaluated on 7 labels of decades (1950s - 2020s), each decade consisting of multiple dance videos. </p>

<img width="640" alt="jump_state1" src="https://github.com/edolior/Video-Movement-Detection-Model/assets/44165771/e14cf28c-1621-4a3d-a8c6-c44edec55462">
